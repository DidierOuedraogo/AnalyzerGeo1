"""
Analyseur G√©ologique de Veines Min√©ralis√©es - Compatible Leapfrog Geo
Auteur: Didier Ouedraogo, P.Geo
Version: 1.2 - Streamlit Cloud Compatible
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import io
import base64
from datetime import datetime
import math
from scipy.spatial.distance import cdist
from sklearn.cluster import DBSCAN
from sklearn.linear_model import LinearRegression
import warnings
warnings.filterwarnings('ignore')

# Configuration de la page
st.set_page_config(
    page_title="Analyseur G√©ologique - Leapfrog Compatible",
    page_icon="‚õèÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√©
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #1e3a8a 0%, #1e40af 100%);
        padding: 2rem;
        border-radius: 1rem;
        color: white;
        margin-bottom: 2rem;
        text-align: center;
    }
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #3b82f6;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .leapfrog-box {
        background: #f0f9ff;
        border: 2px solid #0ea5e9;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
    .success-box {
        background: #f0fdf4;
        border: 1px solid #22c55e;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
    .warning-box {
        background: #fffbeb;
        border: 1px solid #f59e0b;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
    .error-box {
        background: #fef2f2;
        border: 1px solid #ef4444;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Initialisation des √©tats de session
if 'samples_data' not in st.session_state:
    st.session_state.samples_data = None
if 'structural_data' not in st.session_state:
    st.session_state.structural_data = None
if 'mesh_data' not in st.session_state:
    st.session_state.mesh_data = None
if 'results_data' not in st.session_state:
    st.session_state.results_data = None
if 'leapfrog_intervals' not in st.session_state:
    st.session_state.leapfrog_intervals = None

# Classes et fonctions pour compatibilit√© Leapfrog
class LeapfrogGeologicalAnalyzer:
    def __init__(self):
        # Colonnes standard Leapfrog pour les √©chantillons (Assay Table)
        self.leapfrog_assay_columns = {
            'HOLEID': 'Identifiant du forage',
            'FROM': 'Profondeur d√©but (m)',
            'TO': 'Profondeur fin (m)',
            'SAMPLE_ID': 'Identifiant √©chantillon',
            'Au': 'Teneur or (g/t)',
            'Ag': 'Teneur argent (g/t)',
            'Cu': 'Teneur cuivre (%)',
            'LENGTH': 'Longueur √©chantillon (m)',
            'RECOVERY': 'R√©cup√©ration (%)',
            'DENSITY': 'Densit√© (t/m¬≥)'
        }
        
        # Colonnes standard Leapfrog pour les intervalles (Interval Table)
        self.leapfrog_interval_columns = {
            'HOLEID': 'Identifiant du forage',
            'FROM': 'Profondeur d√©but (m)',
            'TO': 'Profondeur fin (m)',
            'DOMAIN': 'Domaine g√©ologique',
            'ZONE': 'Zone min√©ralis√©e',
            'ROCK_TYPE': 'Type de roche',
            'ALTERATION': 'Type d\'alt√©ration',
            'MINERALIZATION': 'Type de min√©ralisation',
            'VEIN_ID': 'Identifiant de veine',
            'CONFIDENCE': 'Niveau de confiance',
            'STRUCTURE_TYPE': 'Type de structure',
            'COMMENTS': 'Commentaires'
        }
        
        # Colonnes pour les donn√©es structurales compatibles Leapfrog
        self.leapfrog_structural_columns = {
            'STRUCTURE_ID': 'Identifiant de structure',
            'X': 'Coordonn√©e X',
            'Y': 'Coordonn√©e Y',
            'Z': 'Coordonn√©e Z',
            'STRIKE': 'Direction (¬∞)',
            'DIP': 'Pendage (¬∞)',
            'DIP_DIRECTION': 'Direction de pendage (¬∞)',
            'STRUCTURE_TYPE': 'Type de structure',
            'CONFIDENCE': 'Niveau de confiance',
            'MEASUREMENT_TYPE': 'Type de mesure',
            'VEIN_SET': 'Famille de veines',
            'CAMPAIGN': 'Campagne de mesure',
            'DATE_MEASURED': 'Date de mesure',
            'COMMENTS': 'Commentaires'
        }
    
    def auto_detect_leapfrog_columns(self, df_columns):
        """Auto-d√©tection des colonnes compatibles Leapfrog"""
        mapping = {}
        
        for leapfrog_col, description in self.leapfrog_assay_columns.items():
            # Recherche exacte
            exact_match = next((col for col in df_columns 
                              if col.upper().strip() == leapfrog_col.upper()), None)
            
            if exact_match:
                mapping[leapfrog_col] = exact_match
                continue
            
            # Recherche alternative
            for col in df_columns:
                col_upper = col.upper().strip()
                
                if leapfrog_col == 'HOLEID' and any(word in col_upper for word in ['HOLE', 'DRILL', 'DDH', 'BH', 'SONDAGE', 'ID']):
                    mapping[leapfrog_col] = col
                    break
                elif leapfrog_col == 'FROM' and any(word in col_upper for word in ['FROM', 'DEBUT', 'START', 'DE']):
                    mapping[leapfrog_col] = col
                    break
                elif leapfrog_col == 'TO' and any(word in col_upper for word in ['TO', 'FIN', 'END', 'A']):
                    mapping[leapfrog_col] = col
                    break
                elif leapfrog_col == 'Au' and any(word in col_upper for word in ['AU', 'GOLD', 'OR', 'TENEUR']):
                    mapping[leapfrog_col] = col
                    break
        
        return mapping
    
    def validate_leapfrog_data(self, df, mapping):
        """Validation des donn√©es pour Leapfrog"""
        errors = []
        warnings = []
        
        # V√©rifier les colonnes obligatoires
        required_cols = ['HOLEID', 'FROM', 'TO']
        for req_col in required_cols:
            if req_col not in mapping or not mapping[req_col]:
                errors.push(f"Colonne obligatoire '{req_col}' manquante")
        
        if errors:
            return None, errors, warnings
        
        # Validation des donn√©es
        mapped_df = pd.DataFrame()
        
        for leapfrog_col, source_col in mapping.items():
            if source_col and source_col in df.columns:
                if leapfrog_col in ['FROM', 'TO', 'Au', 'Ag', 'Cu', 'LENGTH', 'RECOVERY', 'DENSITY']:
                    mapped_df[leapfrog_col] = pd.to_numeric(df[source_col], errors='coerce')
                else:
                    mapped_df[leapfrog_col] = df[source_col].astype(str)
        
        # Calculer LENGTH si manquant
        if 'FROM' in mapped_df.columns and 'TO' in mapped_df.columns and 'LENGTH' not in mapped_df.columns:
            mapped_df['LENGTH'] = mapped_df['TO'] - mapped_df['FROM']
            warnings.append("Colonne LENGTH calcul√©e automatiquement")
        
        # Ajouter SAMPLE_ID si manquant
        if 'SAMPLE_ID' not in mapped_df.columns:
            mapped_df['SAMPLE_ID'] = mapped_df['HOLEID'] + '_' + mapped_df['FROM'].astype(str) + '_' + mapped_df['TO'].astype(str)
            warnings.append("SAMPLE_ID g√©n√©r√© automatiquement")
        
        # Supprimer les lignes avec des valeurs critiques manquantes
        initial_count = len(mapped_df)
        mapped_df = mapped_df.dropna(subset=['HOLEID', 'FROM', 'TO'])
        final_count = len(mapped_df)
        
        if initial_count > final_count:
            warnings.append(f"{initial_count - final_count} lignes supprim√©es (valeurs manquantes)")
        
        return mapped_df, errors, warnings
    
    def create_leapfrog_intervals(self, samples_df, params):
        """Cr√©ation d'intervalles compatibles Leapfrog"""
        if samples_df is None or len(samples_df) == 0:
            return pd.DataFrame()
        
        intervals = []
        min_grade = params.get('min_grade', 0.5)
        max_dilution = params.get('max_dilution', 3.0)
        min_samples = params.get('min_samples', 2)
        
        # Grouper par forage
        for holeid, hole_data in samples_df.groupby('HOLEID'):
            hole_data = hole_data.sort_values('FROM').reset_index(drop=True)
            
            current_interval = None
            zone_id = 1
            
            for idx, sample in hole_data.iterrows():
                grade = sample.get('Au', 0) if pd.notna(sample.get('Au', 0)) else 0
                is_ore = grade >= min_grade
                
                if is_ore:
                    if current_interval is None:
                        current_interval = {'samples': [sample], 'start_idx': idx}
                    else:
                        last_sample = current_interval['samples'][-1]
                        gap = sample['FROM'] - last_sample['TO']
                        
                        if gap <= max_dilution:
                            current_interval['samples'].append(sample)
                        else:
                            if len(current_interval['samples']) >= min_samples:
                                interval = self._create_leapfrog_interval(current_interval, holeid, zone_id)
                                intervals.append(interval)
                                zone_id += 1
                            current_interval = {'samples': [sample], 'start_idx': idx}
                else:
                    if current_interval is not None:
                        if len(current_interval['samples']) >= min_samples:
                            interval = self._create_leapfrog_interval(current_interval, holeid, zone_id)
                            intervals.append(interval)
                            zone_id += 1
                        current_interval = None
            
            # Finaliser le dernier intervalle
            if current_interval is not None and len(current_interval['samples']) >= min_samples:
                interval = self._create_leapfrog_interval(current_interval, holeid, zone_id)
                intervals.append(interval)
        
        if intervals:
            intervals_df = pd.DataFrame(intervals)
            return self._add_leapfrog_metadata(intervals_df, params)
        else:
            return pd.DataFrame()
    
    def _create_leapfrog_interval(self, interval_data, holeid, zone_id):
        """Cr√©er un intervalle au format Leapfrog"""
        samples = pd.DataFrame(interval_data['samples'])
        
        from_depth = samples['FROM'].min()
        to_depth = samples['TO'].max()
        true_width = to_depth - from_depth
        
        total_length = samples['LENGTH'].sum() if 'LENGTH' in samples.columns else true_width
        weighted_grade = (samples['Au'] * samples.get('LENGTH', 1)).sum() / total_length if total_length > 0 else 0
        
        return {
            'HOLEID': holeid,
            'FROM': round(from_depth, 2),
            'TO': round(to_depth, 2),
            'DOMAIN': self._classify_domain(weighted_grade),
            'ZONE': f"ZONE_{zone_id:03d}",
            'VEIN_ID': f"VEIN_{zone_id:03d}",
            'CONFIDENCE': round(min(0.95, 0.5 + len(samples) * 0.1), 2),
            'STRUCTURE_TYPE': 'VEIN',
            'TRUE_WIDTH': round(true_width, 2),
            'WEIGHTED_GRADE': round(weighted_grade, 3),
            'SAMPLE_COUNT': len(samples),
            'METAL_CONTENT': round(weighted_grade * true_width, 3)
        }
    
    def _classify_domain(self, grade):
        """Classification en domaine g√©ologique"""
        if grade >= 5.0:
            return 'HIGH_GRADE'
        elif grade >= 2.0:
            return 'ORE_ZONE'
        elif grade >= 0.5:
            return 'LOW_GRADE'
        else:
            return 'WASTE'
    
    def _add_leapfrog_metadata(self, intervals_df, params):
        """Ajouter les m√©tadonn√©es Leapfrog"""
        if len(intervals_df) == 0:
            return intervals_df
        
        intervals_df['CAMPAIGN'] = params.get('campaign', 'DEFAULT_CAMPAIGN')
        intervals_df['DATE_CREATED'] = datetime.now().strftime('%Y-%m-%d')
        intervals_df['CREATED_BY'] = 'GEOLOGICAL_ANALYZER'
        
        return intervals_df
    
    def export_leapfrog_format(self, data_type, df, filename_prefix):
        """Export au format standard Leapfrog"""
        if df is None or len(df) == 0:
            return None
        
        header_lines = [
            f"# Leapfrog Geo Compatible Export - {data_type}",
            f"# Generated by: Geological Analyzer v1.2",
            f"# Author: Didier Ouedraogo, P.Geo",
            f"# Export Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"# Total Records: {len(df)}",
            f"# Coordinate System: UTM Zone 18N (EPSG:32618)",
            f"# Units: Meters (length), PPM (grade)",
            "#"
        ]
        
        csv_buffer = io.StringIO()
        
        for line in header_lines:
            csv_buffer.write(line + '\n')
        
        df.to_csv(csv_buffer, index=False, float_format='%.3f')
        
        csv_content = csv_buffer.getvalue()
        csv_buffer.close()
        
        return csv_content

def generate_leapfrog_demo_data():
    """G√©n√©ration de donn√©es de d√©monstration compatibles Leapfrog"""
    np.random.seed(42)
    
    # Param√®tres du gisement aurif√®re
    deposit_center = {'x': 450000, 'y': 5100000, 'z': 350}
    
    # Syst√®mes de veines aurif√®res
    vein_systems = [
        {
            'id': 'MAIN_LODE', 'strike': 45, 'dip': 65, 'center_x': 450000, 'center_y': 5100000,
            'avg_grade': 8.5, 'width': 2.5, 'continuity': 0.85
        },
        {
            'id': 'HANGING_WALL', 'strike': 50, 'dip': 70, 'center_x': 450150, 'center_y': 5100100,
            'avg_grade': 4.2, 'width': 1.5, 'continuity': 0.65
        }
    ]
    
    # G√©n√©ration des √©chantillons
    samples = []
    
    for hole_num in range(1, 51):  # 50 forages
        hole_id = f"DDH{hole_num:04d}"
        
        grid_x = ((hole_num - 1) % 10) * 40
        grid_y = ((hole_num - 1) // 10) * 40
        hole_x = deposit_center['x'] - 200 + grid_x + np.random.normal(0, 5)
        hole_y = deposit_center['y'] - 200 + grid_y + np.random.normal(0, 5)
        hole_z = deposit_center['z'] + np.random.uniform(-15, 15)
        
        max_depth = np.random.uniform(200, 400)
        sample_length = 1.5
        num_samples = int(max_depth / sample_length)
        
        for i in range(num_samples):
            from_depth = i * sample_length
            to_depth = (i + 1) * sample_length
            
            sample_x = hole_x + np.random.normal(0, 1)
            sample_y = hole_y + np.random.normal(0, 1)
            sample_z = hole_z - (from_depth + to_depth) / 2
            
            au_grade = np.random.lognormal(np.log(0.05), 0.5)
            ag_grade = au_grade * np.random.uniform(5, 20)
            cu_grade = np.random.uniform(0.01, 0.1)
            
            # Influence des veines
            for vein in vein_systems:
                distance_to_vein = np.sqrt(
                    (sample_x - vein['center_x'])**2 + 
                    (sample_y - vein['center_y'])**2
                )
                
                spatial_influence = np.exp(-distance_to_vein / 80)
                intersection_prob = spatial_influence * vein['continuity']
                
                if np.random.random() < intersection_prob * 0.4:
                    grade_factor = vein['avg_grade'] * np.random.uniform(0.7, 1.3)
                    au_grade = max(au_grade, grade_factor)
                    ag_grade = au_grade * np.random.uniform(10, 30)
            
            au_grade = min(au_grade, 100.0)
            ag_grade = min(ag_grade, 2000.0)
            
            samples.append({
                'HOLEID': hole_id,
                'FROM': round(from_depth, 1),
                'TO': round(to_depth, 1),
                'SAMPLE_ID': f"{hole_id}_{from_depth:06.1f}_{to_depth:06.1f}",
                'Au': round(au_grade, 3),
                'Ag': round(ag_grade, 2),
                'Cu': round(cu_grade, 3),
                'LENGTH': sample_length,
                'RECOVERY': round(np.random.uniform(85, 98), 1),
                'DENSITY': round(np.random.uniform(2.5, 2.9), 2),
                'XCOLLAR': round(hole_x, 2),
                'YCOLLAR': round(hole_y, 2),
                'ZCOLLAR': round(hole_z, 2)
            })
    
    # Donn√©es structurales
    structural_data = []
    for i, vein in enumerate(vein_systems):
        for j in range(5):
            measurement_x = vein['center_x'] + np.random.uniform(-100, 100)
            measurement_y = vein['center_y'] + np.random.uniform(-100, 100)
            measurement_z = deposit_center['z'] - np.random.uniform(50, 300)
            
            strike_var = vein['strike'] + np.random.normal(0, 5)
            dip_var = vein['dip'] + np.random.normal(0, 3)
            
            structural_data.append({
                'STRUCTURE_ID': f"{vein['id']}_M{j+1:02d}",
                'X': round(measurement_x, 2),
                'Y': round(measurement_y, 2),
                'Z': round(measurement_z, 2),
                'STRIKE': round(strike_var, 1),
                'DIP': round(dip_var, 1),
                'DIP_DIRECTION': round((strike_var + 90) % 360, 1),
                'STRUCTURE_TYPE': 'VEIN',
                'CONFIDENCE': round(np.random.uniform(0.7, 0.95), 2),
                'MEASUREMENT_TYPE': 'ORIENTED_CORE',
                'VEIN_SET': vein['id']
            })
    
    # Mesh g√©ologique
    mesh_data = []
    fault_strike = 120
    fault_dip = 80
    
    for i in range(100):
        along_strike = np.random.uniform(-300, 300)
        along_dip = np.random.uniform(-200, 200)
        
        x = deposit_center['x'] + along_strike * np.cos(np.radians(fault_strike))
        y = deposit_center['y'] + along_strike * np.sin(np.radians(fault_strike))
        z = deposit_center['z'] - along_dip * np.sin(np.radians(fault_dip))
        
        mesh_data.append({
            'x': round(x, 2),
            'y': round(y, 2),
            'z': round(z, 2),
            'structure_id': 'MAJOR_FAULT'
        })
    
    return pd.DataFrame(samples), pd.DataFrame(structural_data), pd.DataFrame(mesh_data)

def create_leapfrog_qaqc_plots(df):
    """Cr√©ation de graphiques QA/QC compatibles Leapfrog - CORRIG√â"""
    
    # Distribution des teneurs (log-scale pour l'or)
    fig1 = px.histogram(
        df, 
        x='Au', 
        nbins=50,
        title="Distribution des Teneurs en Or (Au)",
        labels={'Au': 'Teneur Au (ppm)', 'count': 'Fr√©quence'},
        log_x=True
    )
    fig1.add_vline(x=0.5, line_dash="dash", line_color="red", 
                   annotation_text="Cut-off 0.5 ppm")
    
    # Corr√©lation Au-Ag SANS trendline OLS
    sample_df = df.sample(min(1000, len(df))) if len(df) > 1000 else df
    
    fig2 = px.scatter(
        sample_df, 
        x='Au', y='Ag',
        title="Corr√©lation Au-Ag",
        labels={'Au': 'Teneur Au (ppm)', 'Ag': 'Teneur Ag (ppm)'}
    )
    
    # Ajouter une ligne de tendance manuelle avec sklearn
    if len(sample_df) > 1 and sample_df['Au'].std() > 0:
        try:
            # Pr√©parer les donn√©es pour la r√©gression
            X = sample_df['Au'].values.reshape(-1, 1)
            y = sample_df['Ag'].values
            
            # Supprimer les valeurs NaN
            mask = ~(np.isnan(X.flatten()) | np.isnan(y))
            X_clean = X[mask]
            y_clean = y[mask]
            
            if len(X_clean) > 1:
                # R√©gression lin√©aire
                reg = LinearRegression()
                reg.fit(X_clean, y_clean)
                
                # Ligne de tendance
                x_range = np.linspace(X_clean.min(), X_clean.max(), 100)
                y_pred = reg.predict(x_range.reshape(-1, 1))
                
                fig2.add_trace(go.Scatter(
                    x=x_range.flatten(),
                    y=y_pred,
                    mode='lines',
                    name=f'Tendance (R¬≤={reg.score(X_clean, y_clean):.3f})',
                    line=dict(color='red', dash='dash')
                ))
        except Exception:
            pass  # Si erreur, on continue sans la ligne de tendance
    
    # Distribution spatiale des teneurs
    fig3 = None
    if 'XCOLLAR' in df.columns and 'YCOLLAR' in df.columns:
        hole_summary = df.groupby('HOLEID').agg({
            'XCOLLAR': 'first',
            'YCOLLAR': 'first',
            'Au': 'mean'
        }).reset_index()
        
        fig3 = px.scatter(
            hole_summary,
            x='XCOLLAR', y='YCOLLAR',
            color='Au',
            size='Au',
            title="Distribution Spatiale des Teneurs",
            labels={'XCOLLAR': 'X (UTM)', 'YCOLLAR': 'Y (UTM)', 'Au': 'Au (ppm)'},
            color_continuous_scale='Viridis'
        )
    
    # Profil de teneur par profondeur
    try:
        depth_bins = pd.cut(df['FROM'], bins=20)
        depth_profile = df.groupby(depth_bins)['Au'].mean().reset_index()
        depth_profile['Depth_Mid'] = depth_profile['FROM'].apply(lambda x: x.mid if hasattr(x, 'mid') else 0)
        
        fig4 = px.line(
            depth_profile,
            x='Depth_Mid', y='Au',
            title="Profil de Teneur par Profondeur",
            labels={'Depth_Mid': 'Profondeur (m)', 'Au': 'Teneur Moyenne Au (ppm)'}
        )
    except Exception:
        # Fallback simple
        fig4 = px.scatter(
            df.sample(min(500, len(df))),
            x='FROM', y='Au',
            title="Teneur vs Profondeur",
            labels={'FROM': 'Profondeur (m)', 'Au': 'Teneur Au (ppm)'}
        )
    
    return fig1, fig2, fig3, fig4

def create_compass_plot(strike, dip, vein_id):
    """Cr√©ation d'un diagramme en boussole"""
    fig = go.Figure()
    
    # Cercle ext√©rieur
    theta = np.linspace(0, 2*np.pi, 100)
    x_circle = np.cos(theta)
    y_circle = np.sin(theta)
    
    fig.add_trace(go.Scatter(
        x=x_circle, y=y_circle,
        mode='lines',
        line=dict(color='lightgray', width=2),
        showlegend=False
    ))
    
    # Directions cardinales
    fig.add_annotation(x=0, y=1.1, text="N", showarrow=False, font=dict(size=14, color='red'))
    fig.add_annotation(x=1.1, y=0, text="E", showarrow=False, font=dict(size=14))
    fig.add_annotation(x=0, y=-1.1, text="S", showarrow=False, font=dict(size=14))
    fig.add_annotation(x=-1.1, y=0, text="W", showarrow=False, font=dict(size=14))
    
    # Ligne de strike
    strike_rad = np.radians(strike)
    x_strike = [np.sin(strike_rad), -np.sin(strike_rad)]
    y_strike = [np.cos(strike_rad), -np.cos(strike_rad)]
    
    fig.add_trace(go.Scatter(
        x=x_strike, y=y_strike,
        mode='lines',
        line=dict(color='blue', width=4),
        name=f'Strike: {strike}¬∞'
    ))
    
    # Indicateur de pendage
    dip_length = 0.7
    dip_x = dip_length * np.sin(strike_rad + np.pi/2)
    dip_y = dip_length * np.cos(strike_rad + np.pi/2)
    
    fig.add_trace(go.Scatter(
        x=[0, dip_x], y=[0, dip_y],
        mode='lines+markers',
        line=dict(color='red', width=3, dash='dash'),
        marker=dict(size=8, color='red'),
        name=f'Dip: {dip}¬∞'
    ))
    
    fig.update_layout(
        title=f"Mesure Structurale: {vein_id}",
        xaxis=dict(range=[-1.3, 1.3], showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(range=[-1.3, 1.3], showgrid=False, zeroline=False, showticklabels=False),
        aspectratio=dict(x=1, y=1),
        height=400,
        showlegend=True
    )
    
    return fig

def create_stereonet_plot(structural_df):
    """Cr√©ation d'un st√©r√©onet"""
    fig = go.Figure()
    
    # Cercle de r√©f√©rence
    theta = np.linspace(0, 2*np.pi, 100)
    fig.add_trace(go.Scatter(
        x=np.cos(theta), y=np.sin(theta),
        mode='lines',
        line=dict(color='lightgray', width=2),
        showlegend=False
    ))
    
    # Grille de r√©f√©rence
    for r in [0.25, 0.5, 0.75]:
        fig.add_trace(go.Scatter(
            x=r*np.cos(theta), y=r*np.sin(theta),
            mode='lines',
            line=dict(color='lightgray', width=1),
            showlegend=False,
            opacity=0.5
        ))
    
    # Points de mesures
    for _, measure in structural_df.iterrows():
        strike_rad = np.radians(measure['STRIKE'])
        dip_rad = np.radians(measure['DIP'])
        
        # Projection st√©r√©ographique
        r = np.tan(dip_rad / 2)
        if r <= 1:  # V√©rifier que le point est dans le cercle
            x = r * np.sin(strike_rad)
            y = r * np.cos(strike_rad)
            
            confidence = measure.get('CONFIDENCE', 0.8)
            color = 'green' if confidence > 0.8 else 'orange' if confidence > 0.6 else 'red'
            
            fig.add_trace(go.Scatter(
                x=[x], y=[y],
                mode='markers+text',
                marker=dict(size=10, color=color),
                text=measure['STRUCTURE_ID'] if 'STRUCTURE_ID' in measure else 'STRUCT',
                textposition='top center',
                name=f"{measure.get('STRUCTURE_ID', 'STRUCT')} ({measure['STRIKE']:.0f}¬∞/{measure['DIP']:.0f}¬∞)"
            ))
    
    fig.update_layout(
        title="Projection St√©r√©ographique",
        xaxis=dict(range=[-1.2, 1.2], showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(range=[-1.2, 1.2], showgrid=False, zeroline=False, showticklabels=False),
        aspectratio=dict(x=1, y=1),
        height=500
    )
    
    return fig

def create_rose_diagram(structural_df):
    """Cr√©ation d'un diagramme en rosace"""
    # Grouper les directions par secteurs de 15¬∞
    bin_size = 15
    bins = np.arange(0, 361, bin_size)
    strikes = structural_df['STRIKE'].values
    
    hist, bin_edges = np.histogram(strikes, bins=bins)
    
    # Cr√©er le diagramme polaire
    fig = go.Figure()
    
    for i, count in enumerate(hist):
        if count > 0:
            theta_start = bin_edges[i]
            theta_end = bin_edges[i + 1]
            theta_mid = (theta_start + theta_end) / 2
            
            fig.add_trace(go.Barpolar(
                r=[count],
                theta=[theta_mid],
                width=[bin_size],
                name=f"{theta_start}¬∞-{theta_end}¬∞",
                showlegend=False
            ))
    
    fig.update_layout(
        title="Diagramme en Rosace - Directions",
        polar=dict(
            radialaxis=dict(visible=True, range=[0, max(hist) if len(hist) > 0 else 1]),
            angularaxis=dict(direction='clockwise', rotation=90)
        ),
        height=500
    )
    
    return fig

def main():
    # En-t√™te principal avec badge Leapfrog
    st.markdown("""
    <div class="main-header">
        <h1>‚õèÔ∏è Analyseur G√©ologique - Compatible Leapfrog Geo</h1>
        <h2>üéØ Export Direct vers Leapfrog | Standards Industriels</h2>
        <p style="margin-top: 1rem; opacity: 0.9;">
            Version Streamlit Cloud - Optimis√©e et Compatible
        </p>
        <div style="background: rgba(255,255,255,0.2); border-radius: 0.5rem; padding: 1rem; margin-top: 1.5rem;">
            <div style="display: flex; justify-content: space-between; align-items: center;">
                <div>
                    <h4>üë®‚Äçüî¨ Auteur</h4>
                    <h3>Didier Ouedraogo, P.Geo</h3>
                    <p>G√©ologue Professionnel | Sp√©cialiste Leapfrog Geo & Mod√©lisation 3D</p>
                </div>
                <div style="text-align: right;">
                    <p>üìÖ Version: 1.2 - Streamlit Cloud</p>
                    <p>üéØ Standards: Leapfrog Geo 2024</p>
                    <p>Date: {datetime.now().strftime('%B %Y')}</p>
                </div>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # Badge de compatibilit√© Leapfrog
    st.markdown("""
    <div class="leapfrog-box">
        <h4>üéØ Compatibilit√© Leapfrog Geo Certifi√©e</h4>
        <p><strong>‚úÖ Formats support√©s:</strong> Assay Table, Interval Table, Structural Data</p>
        <p><strong>‚úÖ Standards respect√©s:</strong> Nomenclature Leapfrog, unit√©s m√©triques, CRS standardis√©</p>
        <p><strong>‚úÖ Import direct:</strong> Fichiers pr√™ts pour import dans Leapfrog Geo</p>
        <p><strong>‚úÖ Streamlit Cloud:</strong> Optimis√© pour d√©ploiement cloud</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Initialiser l'analyseur Leapfrog
    analyzer = LeapfrogGeologicalAnalyzer()
    
    # Sidebar pour la navigation
    st.sidebar.title("üß≠ Navigation Leapfrog")
    tab_selected = st.sidebar.selectbox(
        "S√©lectionner une section:",
        ["üì§ Import & D√©monstration", "üîó Mapping Leapfrog", "‚öôÔ∏è Analyse & Intervalles", "üìä Export Leapfrog"]
    )
    
    # Section Import & D√©monstration
    if tab_selected == "üì§ Import & D√©monstration":
        st.header("üì§ Import Multi-Format avec Donn√©es Demo Leapfrog")
        
        # G√©n√©ration de donn√©es demo compatibles Leapfrog
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("""
            <div class="success-box">
                <h4>üöÄ Donn√©es de D√©monstration Leapfrog</h4>
                <p>G√©n√®re un gisement aurif√®re r√©aliste avec:</p>
                <ul>
                    <li>50 forages DDH format standard</li>
                    <li>~3000 √©chantillons Au-Ag-Cu</li>
                    <li>2 syst√®mes de veines aurif√®res</li>
                    <li>Donn√©es structurales compl√®tes</li>
                    <li>Mesh de faille majeure</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            if st.button("‚ö° G√©n√©rer Dataset Leapfrog", type="primary"):
                with st.spinner("G√©n√©ration du gisement aurif√®re..."):
                    samples_demo, structural_demo, mesh_demo = generate_leapfrog_demo_data()
                    st.session_state.samples_data = samples_demo
                    st.session_state.structural_data = structural_demo
                    st.session_state.mesh_data = mesh_demo
                    st.success(f"""
                    ‚úÖ **Dataset Leapfrog G√©n√©r√©!**
                    
                    üìä **Donn√©es cr√©√©es:**
                    - {len(samples_demo):,} √©chantillons Au-Ag-Cu
                    - {samples_demo['HOLEID'].nunique()} forages DDH
                    - {len(structural_demo)} mesures structurales
                    - {len(mesh_demo)} points de mesh de faille
                    """)
        
        # Statistiques et QA/QC
        if st.session_state.samples_data is not None:
            st.markdown("---")
            st.subheader("üìä QA/QC et Statistiques Leapfrog")
            
            samples_df = st.session_state.samples_data
            
            # M√©triques principales
            col1, col2, col3, col4, col5 = st.columns(5)
            
            with col1:
                st.metric("üìä √âchantillons", f"{len(samples_df):,}")
            with col2:
                st.metric("üèóÔ∏è Forages", samples_df['HOLEID'].nunique())
            with col3:
                avg_au = samples_df['Au'].mean()
                st.metric("ü•á Au Moyen", f"{avg_au:.2f} ppm")
            with col4:
                max_au = samples_df['Au'].max()
                st.metric("‚≠ê Au Max", f"{max_au:.1f} ppm")
            with col5:
                mineralized = len(samples_df[samples_df['Au'] >= 0.5])
                pct_min = mineralized / len(samples_df) * 100
                st.metric("üíé Min√©ralis√©", f"{pct_min:.1f}%")
            
            # Graphiques QA/QC
            st.subheader("üìà Graphiques QA/QC Leapfrog")
            
            with st.spinner("G√©n√©ration des graphiques QA/QC..."):
                fig1, fig2, fig3, fig4 = create_leapfrog_qaqc_plots(samples_df)
                
                tab1, tab2, tab3, tab4 = st.tabs(["üìä Distribution Au", "üîó Corr√©lation Au-Ag", "üó∫Ô∏è Spatial", "üìâ Profondeur"])
                
                with tab1:
                    st.plotly_chart(fig1, use_container_width=True)
                
                with tab2:
                    st.plotly_chart(fig2, use_container_width=True)
                    correlation = samples_df['Au'].corr(samples_df['Ag'])
                    st.metric("Corr√©lation Au-Ag", f"{correlation:.3f}")
                
                with tab3:
                    if fig3:
                        st.plotly_chart(fig3, use_container_width=True)
                    else:
                        st.warning("‚ö†Ô∏è Coordonn√©es spatiales non disponibles")
                
                with tab4:
                    st.plotly_chart(fig4, use_container_width=True)
    
    # Section Mapping Leapfrog
    elif tab_selected == "üîó Mapping Leapfrog":
        st.header("üîó Mapping des Colonnes Format Leapfrog")
        
        st.markdown("""
        <div class="leapfrog-box">
            <h4>üéØ Auto-d√©tection Format Leapfrog</h4>
            <p>Le syst√®me d√©tecte automatiquement les colonnes selon les standards Leapfrog:</p>
            <ul>
                <li><strong>HOLEID:</strong> Identifiant unique du forage</li>
                <li><strong>FROM/TO:</strong> Intervalles en m√®tres</li>
                <li><strong>Au/Ag/Cu:</strong> Teneurs en ppm ou %</li>
                <li><strong>SAMPLE_ID:</strong> Identifiant √©chantillon</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
        
        if st.session_state.samples_data is not None:
            st.success("‚úÖ Donn√©es d√©j√† disponibles au format Leapfrog!")
            st.dataframe(st.session_state.samples_data.head(10))
        else:
            st.warning("‚ö†Ô∏è G√©n√©rez d'abord des donn√©es de d√©monstration")
    
    # Section Analyse & Intervalles
    elif tab_selected == "‚öôÔ∏è Analyse & Intervalles":
        st.header("‚öôÔ∏è Cr√©ation d'Intervalles Leapfrog")
        
        if st.session_state.samples_data is None:
            st.warning("‚ö†Ô∏è G√©n√©rez d'abord des donn√©es de d√©monstration")
            return
        
        samples_df = st.session_state.samples_data
        
        st.markdown("""
        <div class="leapfrog-box">
            <h4>üéØ Cr√©ation d'Intervalles pour Leapfrog Geo</h4>
            <p>G√©n√©ration d'intervalles min√©ralis√©s selon les standards Leapfrog avec:</p>
            <ul>
                <li><strong>DOMAIN:</strong> Classification automatique des domaines</li>
                <li><strong>CONFIDENCE:</strong> Score de confiance calcul√©</li>
                <li><strong>ZONE:</strong> Identification des zones min√©ralis√©es</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
        
        # Param√®tres d'analyse
        st.subheader("üîß Param√®tres d'Analyse")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            min_grade = st.number_input("Cut-off Au (ppm)", min_value=0.0, value=0.5, step=0.1)
        with col2:
            max_dilution = st.number_input("Dilution max (m)", min_value=0.1, value=3.0, step=0.5)
        with col3:
            min_samples = st.number_input("√âchantillons min", min_value=1, value=2)
        
        # Aper√ßu des crit√®res
        qualifying_samples = samples_df[samples_df['Au'] >= min_grade]
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("√âchantillons Qualifi√©s", f"{len(qualifying_samples):,}")
        with col2:
            st.metric("Pourcentage", f"{len(qualifying_samples)/len(samples_df)*100:.1f}%")
        with col3:
            affected_holes = qualifying_samples['HOLEID'].nunique()
            st.metric("Forages Affect√©s", affected_holes)
        
        # Analyse
        analysis_params = {
            'min_grade': min_grade,
            'max_dilution': max_dilution,
            'min_samples': min_samples,
            'campaign': 'DEMO_ANALYSIS_2024'
        }
        
        if st.button("üöÄ Cr√©er Intervalles Leapfrog", type="primary"):
            with st.spinner("Cr√©ation des intervalles..."):
                intervals_df = analyzer.create_leapfrog_intervals(samples_df, analysis_params)
                
                if len(intervals_df) > 0:
                    st.session_state.leapfrog_intervals = intervals_df
                    
                    st.success(f"""
                    ‚úÖ **Intervalles Cr√©√©s!**
                    - {len(intervals_df)} intervalles g√©n√©r√©s
                    - {intervals_df['HOLEID'].nunique()} forages avec intervalles
                    - {len(intervals_df['DOMAIN'].unique())} domaines g√©ologiques
                    """)
                    
                    # Aper√ßu des r√©sultats
                    st.subheader("üìä Aper√ßu des Intervalles")
                    st.dataframe(intervals_df.head(20))
                    
                    # Statistiques par domaine
                    domain_stats = intervals_df.groupby('DOMAIN').agg({
                        'HOLEID': 'count',
                        'TRUE_WIDTH': 'sum',
                        'WEIGHTED_GRADE': 'mean'
                    }).round(2)
                    
                    st.subheader("üìã Statistiques par Domaine")
                    st.dataframe(domain_stats)
                else:
                    st.error("‚ùå Aucun intervalle g√©n√©r√©. Ajustez les param√®tres.")
    
    # Section Export Leapfrog
    elif tab_selected == "üìä Export Leapfrog":
        st.header("üìä Export Format Leapfrog Geo")
        
        st.markdown("""
        <div class="leapfrog-box">
            <h4>üéØ Export Direct vers Leapfrog Geo</h4>
            <p>Formats d'export compatibles Leapfrog Geo 2024:</p>
            <ul>
                <li><strong>Assay Table:</strong> Donn√©es d'√©chantillons</li>
                <li><strong>Interval Table:</strong> Intervalles min√©ralis√©s</li>
                <li><strong>Structural Data:</strong> Mesures structurales</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
        
        # Export Assay Table
        if st.session_state.samples_data is not None:
            st.subheader("üìä Export Assay Table")
            
            samples_df = st.session_state.samples_data
            st.info(f"Pr√™t √† exporter {len(samples_df):,} √©chantillons de {samples_df['HOLEID'].nunique()} forages")
            
            if st.button("üì• Exporter Assay Table"):
                csv_content = analyzer.export_leapfrog_format("Assay_Table", samples_df, "assay")
                
                st.download_button(
                    label="üíæ T√©l√©charger Assay Table",
                    data=csv_content,
                    file_name=f"leapfrog_assay_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
        
        # Export Interval Table
        if st.session_state.leapfrog_intervals is not None:
            st.subheader("üìã Export Interval Table")
            
            intervals_df = st.session_state.leapfrog_intervals
            st.info(f"Pr√™t √† exporter {len(intervals_df)} intervalles de {len(intervals_df['DOMAIN'].unique())} domaines")
            
            if st.button("üì• Exporter Interval Table"):
                csv_content = analyzer.export_leapfrog_format("Interval_Table", intervals_df, "intervals")
                
                st.download_button(
                    label="üíæ T√©l√©charger Interval Table",
                    data=csv_content,
                    file_name=f"leapfrog_intervals_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
        
        # Export Structural Data
        if st.session_state.structural_data is not None:
            st.subheader("üìê Export Structural Data")
            
            structural_df = st.session_state.structural_data
            st.info(f"Pr√™t √† exporter {len(structural_df)} mesures structurales")
            
            if st.button("üì• Exporter Structural Data"):
                csv_content = analyzer.export_leapfrog_format("Structural_Data", structural_df, "structural")
                
                st.download_button(
                    label="üíæ T√©l√©charger Structural Data",
                    data=csv_content,
                    file_name=f"leapfrog_structural_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
        
        # Instructions d'import
        st.markdown("---")
        st.markdown("""
        ### üìã Instructions Import Leapfrog
        
        **üéØ Ordre d'import recommand√©:**
        1. **Assay Table** ‚Üí Data Files ‚Üí Samples/Assays
        2. **Interval Table** ‚Üí Data Files ‚Üí Intervals
        3. **Structural Data** ‚Üí Data Files ‚Üí Structural Data
        
        **‚öôÔ∏è Param√®tres d'import:**
        - Syst√®me coordonn√©es: UTM Zone 18N
        - Unit√©s: M√®tres, PPM
        - S√©parateur: Virgule (,)
        """)

if __name__ == "__main__":
    main()